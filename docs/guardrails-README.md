# LLM Guardrails Documentation

This document describes the guardrail modules used in MAPER to enforce strict input/output contracts around Large Language Model (LLM) interactions. These guardrails act as defensive layers that validate, sanitize, and normalize LLM inputs and outputs before they are consumed by the rest of the self-adaptive control loop.

The goal of these guardrails is to:
- Prevent malformed or unexpected LLM responses from propagating
- Enforce minimal structural contracts (e.g., valid JSON, expected fields)
- Provide safe fallbacks under uncertainty or LLM failure
- Increase robustness and trustworthiness of LLM-assisted reasoning

The guardrails are divided according to MAPER phases (Analyze and Plan) and roles (LLM generation vs. Judge validation).

---

## Guardrail Architecture Overview

Each LLM interaction typically involves two stages:

1. LLM generation (Analyze or Plan)
2. Judge validation (Analyze Judge or Plan Judge)

For each stage, there are:
- Input guardrails: validate the data sent to the LLM
- Output guardrails: validate and normalize the LLM response

Additionally, shared utilities are provided to detect and extract JSON from free-form text.

---

## guardrail_exception.py

### Purpose

Defines a custom exception type used across all guardrails to signal violations of the LLM contract.

### Description

GuardrailContractError is raised whenever:
- An input is not of the expected type
- An output does not satisfy minimal structural assumptions

This makes guardrail failures explicit and traceable.

### Exception

GuardrailContractError  
Raised when the input or output violates the expected LLM contract (type or structure).

---

## utils.py

### Purpose

Provides shared utility functions to detect and extract JSON objects from arbitrary text generated by LLMs.

LLMs often return explanations mixed with JSON. These utilities allow MAPER to recover the first valid JSON object safely.

---

### contains_valid_json(text)

Checks whether a string contains at least one valid JSON object.

Behavior:
- Scans the string character by character
- Attempts to parse substrings enclosed in balanced braces
- Returns True if any valid JSON object is found
- Returns False otherwise

Used as a lightweight validation step when needed.

---

### extract_first_json(text)

Extracts and returns the first valid JSON object found in the text.

Behavior:
- Scans for balanced `{ ... }` regions
- Attempts to parse them as JSON
- Returns the first successfully parsed JSON dictionary
- Returns None if no valid JSON object is found

This function is the backbone of all output guardrails.

---

## analyze_llm_guardrails.py

### Purpose

Defines guardrails for the Analyze phase LLM, which is responsible for diagnosing the system state and producing analytical insights.

---

### input_analyze_llm_guardrails(input)

Validates the input sent to the Analyze LLM.

Rules:
- Input must be a string
- None or non-string inputs raise GuardrailContractError

No transformation is applied; valid input is passed through unchanged.

---

### output_analyze_llm_guardrails(output)

Validates and normalizes the output produced by the Analyze LLM.

Expected JSON structure:
- recomendations
- analysis

Behavior:
- Extracts the first JSON object from the output
- If extraction fails, returns a safe default:
  - recomendations: "none"
  - analysis: "Invalid or missing analysis output"
- Ensures both fields are strings
- Returns a normalized JSON string

This guarantees that downstream components always receive a consistent structure.

---

## analyze_judge_guardrails.py

### Purpose

Defines guardrails for the Analyze Judge, which evaluates whether the Analyze LLM output is acceptable or trustworthy.

---

### input_analyze_judge_guardrails(input)

Validates the input sent to the Analyze Judge.

Rules:
- Input must be a string
- Invalid inputs raise GuardrailContractError

---

### output_analyze_judge_guardrails(output)

Validates and normalizes the judge’s decision.

Expected JSON structure:
- verdict (boolean)
- comments (string)

Behavior:
- Extracts the first JSON object
- If extraction fails:
  - verdict defaults to False
  - comments explain the failure
- Coerces verdict to boolean
- Ensures comments is a string
- Returns a normalized JSON string

This ensures the system always receives a clear accept/reject decision.

---

## plan_llm_guardrails.py

### Purpose

Defines guardrails for the Plan phase LLM, which proposes concrete adaptation actions.

---

### input_plan_llm_guardrails(input)

Validates the input sent to the Plan LLM.

Rules:
- Input must be a string
- None or invalid types raise GuardrailContractError

---

### output_plan_llm_guardrails(output)

Validates and normalizes the plan produced by the LLM.

Expected JSON structure:
- action (list)
- reason (string)
- optional target field

Behavior:
- Extracts the first JSON object
- If extraction fails:
  - Returns an empty action list
  - Provides an explanatory reason
- Ensures action is always a list
- Preserves optional target if present
- Returns a JSON-formatted string

This ensures execution components always receive a safe, executable plan structure.

---

## plan_judge_guardrails.py

### Purpose

Defines guardrails for the Plan Judge, which validates whether a proposed plan is acceptable, safe, or policy-compliant.

---

### input_plan_judge_guardrails(input)

Validates the input sent to the Plan Judge.

Rules:
- Input must be a string
- Invalid inputs raise GuardrailContractError

---

### output_plan_judge_guardrails(output)

Validates and normalizes the judge’s decision.

Expected JSON structure:
- verdict (boolean)
- comments (string)

Behavior:
- Extracts the first JSON object
- If extraction fails:
  - verdict defaults to False
  - comments explain the invalid response
- Normalizes verdict and comments
- Returns a JSON string

This final validation step acts as a safety gate before execution.

---

## Summary

These guardrails collectively ensure that:

- LLMs can be used safely in critical control loops
- Free-form or malformed outputs do not break the system
- Reasoning under uncertainty remains bounded and auditable
- MAPER maintains resilience even when LLM behavior is imperfect

They form a crucial trust layer between adaptive logic and probabilistic reasoning.


#### Notes

It is important to note that these guardrails were implemented to directly address the SWIM use case. If the user wishes to use the solution in another domain, the guardrails must be adapted.